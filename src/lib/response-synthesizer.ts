import { ChatOpenAI } from "@langchain/openai";
import { Document } from "langchain/document";
import { env } from "./env";
import { QueryAnalysis } from "./query-analyzer";
import { QueryExpansion } from "./query-expander";
import { extractJSONFromString, safeExtractJSON } from "./json-utils";
import { LanguageDetector } from "./language-detector";

const synthesisModel = new ChatOpenAI({
    modelName: env.LLM_MODEL,
    temperature: 0.3, // Balanced creativity for natural communication
    openAIApiKey: env.OPENAI_API_KEY,
});

export interface ResponseSynthesis {
    synthesizedResponse: string;
    reasoningChain: string[];
    confidence: number;
    sourceAttribution: SourceAttribution[];
    responseStyle: 'analytical' | 'explanatory' | 'comparative' | 'narrative';
    completeness: 'complete' | 'partial' | 'needs_followup';
}

type ResponseStyle = 'analytical' | 'explanatory' | 'comparative' | 'narrative';

export interface SourceAttribution {
    source: string;
    relevance: number;
    usedFor: string;
    pageReference?: string;
    contentType: 'text' | 'table' | 'chart' | 'image';
}

export interface ReasoningStep {
    step: number;
    question: string;
    evidence: string[];
    reasoning: string;
    conclusion: string;
    confidence: number;
}

export class ResponseSynthesizer {
    private languageDetector = new LanguageDetector();
    async synthesizeResponse(
        query: string,
        queryAnalysis: QueryAnalysis,
        documents: Document[],
        queryExpansion?: QueryExpansion,
        previousResponse?: string
    ): Promise<ResponseSynthesis> {
        console.log(`ðŸ”„ Synthesizing human-like response for: "${query}"`);

        // Step 1: Analyze the evidence and build reasoning chain
        const reasoningSteps = await this.buildReasoningChain(query, queryAnalysis, documents);

        // Step 2: Determine appropriate response style
        const responseStyle = this.determineResponseStyle(queryAnalysis, documents);

        // Step 3: Create source attributions
        const sourceAttributions = this.createSourceAttributions(documents);

        // Step 4: Synthesize the human-like response
        const synthesizedResponse = await this.generateHumanLikeResponse(
            query,
            queryAnalysis,
            documents,
            reasoningSteps,
            responseStyle,
            sourceAttributions
        );

        // Step 5: Assess response completeness and confidence
        const completeness = await this.assessCompleteness(query, synthesizedResponse, documents);
        const confidence = this.calculateOverallConfidence(reasoningSteps, documents.length);

        return {
            synthesizedResponse,
            reasoningChain: reasoningSteps.map(step => step.reasoning),
            confidence,
            sourceAttribution: sourceAttributions,
            responseStyle,
            completeness
        };
    }

    private async buildReasoningChain(
        query: string,
        analysis: QueryAnalysis,
        documents: Document[]
    ): Promise<ReasoningStep[]> {
        if (analysis.complexity < 3) {
            // Simple queries don't need complex reasoning chains
            return [{
                step: 1,
                question: query,
                evidence: documents.slice(0, 2).map(doc => doc.pageContent.slice(0, 200)),
                reasoning: "Direct answer from available evidence",
                conclusion: "Information found in source documents",
                confidence: 0.8
            }];
        }

        const reasoningPrompt = `Build a logical reasoning chain to answer this query using the provided evidence:

Query: "${query}"
Query Type: ${analysis.queryType}
Complexity: ${analysis.complexity}

Evidence from Documents:
${documents.slice(0, 5).map((doc, i) =>
            `Document ${i + 1}:\n${doc.pageContent.slice(0, 800)}...\n`
        ).join('\n')}

Create a step-by-step reasoning chain:
1. What sub-questions need to be answered?
2. What evidence supports each sub-answer?
3. How do the pieces connect logically?
4. What can we conclude with confidence?

Return as JSON array:
[
  {
    "step": 1,
    "question": "What is the first thing we need to establish?",
    "evidence": ["evidence piece 1", "evidence piece 2"],
    "reasoning": "Why this evidence leads to this conclusion",
    "conclusion": "What we can conclude from this step",
    "confidence": 0.8
  }
]

Build 2-4 logical steps that flow naturally from question to answer.`;

        try {
            const response = await synthesisModel.invoke(reasoningPrompt);
            const steps = extractJSONFromString(response.content as string);
            return Array.isArray(steps) ? steps : [];
        } catch (error) {
            console.warn('Reasoning chain generation failed:', error);
            return [];
        }
    }

    private determineResponseStyle(
        analysis: QueryAnalysis,
        documents: Document[]
    ): 'analytical' | 'explanatory' | 'comparative' | 'narrative' {
        if (analysis.queryType === 'COMPARATIVE') {
            return 'comparative';
        }
        if (analysis.queryType === 'ANALYTICAL' || analysis.queryType === 'INFERENTIAL') {
            return 'analytical';
        }
        if (analysis.complexity >= 4) {
            return 'narrative';
        }
        return 'explanatory';
    }

    private createSourceAttributions(documents: Document[]): SourceAttribution[] {
        return documents.slice(0, 6).map((doc, index) => {
            const metadata = doc.metadata || {};
            const contentType = this.inferContentType(doc);

            return {
                source: metadata.source || `Document ${index + 1}`,
                relevance: this.calculateSourceRelevance(doc),
                usedFor: this.inferUsageContext(doc, contentType),
                pageReference: metadata.pageNumber ? `Page ${metadata.pageNumber}` : undefined,
                contentType
            };
        });
    }

    private inferContentType(doc: Document): 'text' | 'table' | 'chart' | 'image' {
        const content = doc.pageContent.toLowerCase();
        const metadata = doc.metadata || {};

        if (content.includes('visual analysis:') || metadata.hasVisuals) {
            return 'image';
        }
        if (content.includes('table') || metadata.hasTables) {
            return 'table';
        }
        if (content.includes('chart') || content.includes('graph') || metadata.hasCharts) {
            return 'chart';
        }
        return 'text';
    }

    private calculateSourceRelevance(doc: Document): number {
        const contentLength = doc.pageContent.length;
        const metadata = doc.metadata || {};

        let relevance = 0.5; // Base relevance

        // Boost for longer, more detailed content
        if (contentLength > 1000) relevance += 0.2;
        if (contentLength > 2000) relevance += 0.1;

        // Boost for multimodal content
        if (metadata.hasVisuals) relevance += 0.1;
        if (metadata.hasTables) relevance += 0.1;
        if (metadata.hasCharts) relevance += 0.1;

        return Math.min(1.0, relevance);
    }

    private inferUsageContext(
        doc: Document,
        contentType: 'text' | 'table' | 'chart' | 'image'
    ): string {
        const contextMap: Record<'text' | 'table' | 'chart' | 'image', string> = {
            text: 'background information and context',
            table: 'statistical data and numerical evidence',
            chart: 'trends and visual data analysis',
            image: 'visual evidence and illustrations'
        };

        return contextMap[contentType] ?? 'supporting information';
    }

    private async generateHumanLikeResponse(
        query: string,
        analysis: QueryAnalysis,
        documents: Document[],
        reasoningSteps: ReasoningStep[],
        responseStyle: ResponseStyle,
        sourceAttributions: SourceAttribution[]
    ): Promise<string> {
        const stylePrompts: Record<ResponseStyle, string> = {
            analytical: "Provide a brief, structured response with key points.",
            explanatory: "Give a concise explanation focusing only on the essential information.",
            comparative: "Briefly compare the key differences and similarities.",
            narrative: "Present the information briefly in a logical sequence."
        };

        // Get language-specific instructions
        const languageInstructions = this.languageDetector.getLanguagePromptAddition(analysis.languageDetection);

        const synthesisPrompt = `Create an extremely concise, direct response that answers ONLY what was asked.

Query: "${query}"
Response Style: ${responseStyle}
Style Guidance: ${stylePrompts[responseStyle]}

Available Evidence:
${documents.slice(0, 4).map((doc, i) =>
            `Source ${i + 1} (${sourceAttributions[i]?.contentType || 'text'}): ${doc.pageContent.slice(0, 600)}...`
        ).join('\n\n')}

Reasoning Chain:
${reasoningSteps.map(step =>
            `Step ${step.step}: ${step.question}\nReasoning: ${step.reasoning}\nConclusion: ${step.conclusion}`
        ).join('\n\n')}

${languageInstructions}

EXTREME CONCISENESS REQUIREMENTS:

RESPONSE LENGTH:
- Simple questions: 1-2 sentences maximum
- Complex questions: 3-4 sentences maximum
- Only use multiple paragraphs if absolutely necessary
- Never exceed 5 sentences total

CONTENT RESTRICTIONS:
- Answer ONLY the specific question asked
- NO background information unless explicitly requested
- NO historical context unless essential to the answer
- NO explanations of terms unless they're the core of the question
- NO tangential information, even if related
- NO "interesting facts" or "additional context"

STRUCTURE:
- Start with the direct answer immediately
- Use bullet points only for multiple specific facts
- No introductory phrases like "Based on the evidence..." or "Looking at the data..."
- No concluding statements unless they directly answer the question

CORRELATION RULES:
- Only correlate information if it directly answers the question
- Don't explain connections unless they're the answer itself
- Avoid "This connects to..." or "This relates to..." unless it's the core answer

Remember: Be extremely brief. If the user asks "What is X?", just say what X is. Don't explain why X matters, how X was discovered, or what X relates to unless specifically asked.`;

        try {
            const response = await synthesisModel.invoke(synthesisPrompt);
            const content = response.content as string;

            // Validate that we got a proper response, not a generic greeting
            if (content.includes("Hello! How can I help") || content.includes("Hi") || content.length < 50) {
                console.warn('Received generic response, using fallback');
                return this.generateFallbackResponse(query, documents, analysis.languageDetection);
            }

            return content;
        } catch (error) {
            console.error('Response synthesis failed:', error);
            return this.generateFallbackResponse(query, documents, analysis.languageDetection);
        }
    }

    private generateFallbackResponse(query: string, documents: Document[], languageDetection?: any): string {
        if (documents.length === 0) {
            return `I don't have specific information to answer your question: "${query}". Please try rephrasing your question or check if the relevant documents have been uploaded to the system.`;
        }

        // For simple queries like "hi", provide a helpful response based on detected language
        const normalizedQuery = query.toLowerCase().trim();
        if (normalizedQuery === 'hi' || normalizedQuery === 'hello' || normalizedQuery === 'hey' ||
            normalizedQuery === 'namaste' || normalizedQuery === 'namaskar' || normalizedQuery === 'hai' || normalizedQuery === 'helo' ||
            normalizedQuery === 'vanakkam' || normalizedQuery === 'namaskaram' || normalizedQuery === 'namaskara') {

            // Detect language for greeting response
            const detection = languageDetection || this.languageDetector.detectLanguage(query);

            switch (detection.responseLanguage) {
                case 'hindi':
                    return `à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¤¿à¤ à¤—à¤ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œà¥‹à¤‚ à¤¸à¥‡ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤–à¥‹à¤œà¤¨à¥‡ à¤®à¥‡à¤‚ à¤†à¤ªà¤•à¥€ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¤¹à¤¾à¤ à¤¹à¥‚à¤à¥¤ à¤†à¤ª à¤‡à¤¸ à¤¤à¤°à¤¹ à¤•à¥‡ à¤¸à¤µà¤¾à¤² à¤ªà¥‚à¤› à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚:
- "à¤¯à¤¹ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œ à¤•à¤¿à¤¸ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ?"
- "[à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤µà¤¿à¤·à¤¯] à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤à¤‚"
- "[à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤µà¤¿à¤·à¤¯] à¤•à¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤¦à¤¿à¤–à¤¾à¤à¤‚"
- "à¤®à¥à¤–à¥à¤¯ à¤–à¥‹à¤œà¥‡à¤‚ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆà¤‚?"

à¤†à¤ª à¤•à¥à¤¯à¤¾ à¤œà¤¾à¤¨à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚?`;

                case 'hinglish':
                    return `Namaste! Main upload kiye gaye documents se information dhundne mein aapki help karne ke liye yahan hun. Aap is tarah ke questions puch sakte hain:
- "Yeh document kis baare mein hai?"
- "[specific topic] ke baare mein batayiye"
- "[specific subject] ka data dikhayiye"
- "Main findings kya hain?"

Aap kya jaanna chahte hain?`;

                case 'tamil':
                    return `à®µà®£à®•à¯à®•à®®à¯! à®ªà®¤à®¿à®µà¯‡à®±à¯à®±à®ªà¯à®ªà®Ÿà¯à®Ÿ à®†à®µà®£à®™à¯à®•à®³à®¿à®²à®¿à®°à¯à®¨à¯à®¤à¯ à®¤à®•à®µà®²à¯à®•à®³à¯ˆà®•à¯ à®•à®£à¯à®Ÿà®±à®¿à®¯ à®¨à®¾à®©à¯ à®‡à®™à¯à®•à¯‡ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯‡à®©à¯. à®¨à¯€à®™à¯à®•à®³à¯ à®‡à®¨à¯à®¤ à®®à®¾à®¤à®¿à®°à®¿à®¯à®¾à®© à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯ˆà®•à¯ à®•à¯‡à®Ÿà¯à®•à®²à®¾à®®à¯:
- "à®‡à®¨à¯à®¤ à®†à®µà®£à®®à¯ à®Žà®¤à¯ˆà®ªà¯ à®ªà®±à¯à®±à®¿?"
- "[à®•à¯à®±à®¿à®ªà¯à®ªà®¿à®Ÿà¯à®Ÿ à®¤à®²à¯ˆà®ªà¯à®ªà¯] à®ªà®±à¯à®±à®¿ à®šà¯Šà®²à¯à®²à¯à®™à¯à®•à®³à¯"
- "[à®•à¯à®±à®¿à®ªà¯à®ªà®¿à®Ÿà¯à®Ÿ à®µà®¿à®·à®¯à®¤à¯à®¤à®¿à®©à¯] à®¤à®°à®µà¯ˆ à®•à®¾à®Ÿà¯à®Ÿà¯à®™à¯à®•à®³à¯"
- "à®®à¯à®•à¯à®•à®¿à®¯ à®•à®£à¯à®Ÿà¯à®ªà®¿à®Ÿà®¿à®ªà¯à®ªà¯à®•à®³à¯ à®Žà®©à¯à®©?"

à®¨à¯€à®™à¯à®•à®³à¯ à®Žà®©à¯à®© à®¤à¯†à®°à®¿à®¨à¯à®¤à¯à®•à¯Šà®³à¯à®³ à®µà®¿à®°à¯à®®à¯à®ªà¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?`;

                case 'tamil_roman':
                    return `Vanakkam! Upload panna documents-la irundhu information kandupidika naan inga iruken. Neenga inda madhiri questions kekalam:
- "Indha document edha pathi?"
- "[specific topic] pathi sollunga"
- "[specific subject] oda data kaattunga"
- "Main findings enna?"

Neenga enna therinjukka virumburenga?`;

                case 'telugu':
                    return `à°¨à°®à°¸à±à°•à°¾à°°à°‚! à°…à°ªà±â€Œà°²à±‹à°¡à± à°šà±‡à°¸à°¿à°¨ à°ªà°¤à±à°°à°¾à°² à°¨à±à°‚à°¡à°¿ à°¸à°®à°¾à°šà°¾à°°à°¾à°¨à±à°¨à°¿ à°•à°¨à±à°—à±Šà°¨à°¡à°‚à°²à±‹ à°®à±€à°•à± à°¸à°¹à°¾à°¯à°‚ à°šà±‡à°¯à°¡à°¾à°¨à°¿à°•à°¿ à°¨à±‡à°¨à± à°‡à°•à±à°•à°¡ à°‰à°¨à±à°¨à°¾à°¨à±. à°®à±€à°°à± à°ˆ à°°à°•à°®à±ˆà°¨ à°ªà±à°°à°¶à±à°¨à°²à± à°…à°¡à°—à°µà°šà±à°šà±:
- "à°ˆ à°ªà°¤à±à°°à°‚ à°¦à±‡à°¨à°¿ à°—à±à°°à°¿à°‚à°šà°¿?"
- "[à°¨à°¿à°°à±à°¦à°¿à°·à±à°Ÿ à°…à°‚à°¶à°‚] à°—à±à°°à°¿à°‚à°šà°¿ à°šà±†à°ªà±à°ªà°‚à°¡à°¿"
- "[à°¨à°¿à°°à±à°¦à°¿à°·à±à°Ÿ à°µà°¿à°·à°¯à°‚] à°¡à±‡à°Ÿà°¾ à°šà±‚à°ªà°¿à°‚à°šà°‚à°¡à°¿"
- "à°ªà±à°°à°§à°¾à°¨ à°•à°¨à±à°—à±Šà°¨à±à°¨ à°µà°¿à°·à°¯à°¾à°²à± à°à°®à°¿à°Ÿà°¿?"

à°®à±€à°°à± à°à°®à°¿ à°¤à±†à°²à±à°¸à±à°•à±‹à°µà°¾à°²à°¨à°¿ à°…à°¨à±à°•à±à°‚à°Ÿà±à°¨à±à°¨à°¾à°°à±?`;

                case 'telugu_roman':
                    return `Namaskaram! Upload chesina documents nundi information kandukovadamlo miku help cheyadaniki nenu ikkada unnaanu. Meeru ee rakamaina questions adagavacchu:
- "Ee document edi gurinchi?"
- "[specific topic] gurinchi cheppandi"
- "[specific subject] data choopinchandi"
- "Main findings emiti?"

Meeru emi telusukovaali anukuntunnaaru?`;

                case 'kannada':
                    return `à²¨à²®à²¸à³à²•à²¾à²°! à²…à²ªà³â€Œà²²à³‹à²¡à³ à²®à²¾à²¡à²¿à²¦ à²¦à²¾à²–à²²à³†à²—à²³à²¿à²‚à²¦ à²®à²¾à²¹à²¿à²¤à²¿à²¯à²¨à³à²¨à³ à²¹à³à²¡à³à²•à²²à³ à²¨à²¾à²¨à³ à²‡à²²à³à²²à²¿ à²‡à²¦à³à²¦à³‡à²¨à³†. à²¨à³€à²µà³ à²ˆ à²°à³€à²¤à²¿à²¯ à²ªà³à²°à²¶à³à²¨à³†à²—à²³à²¨à³à²¨à³ à²•à³‡à²³à²¬à²¹à³à²¦à³:
- "à²ˆ à²¦à²¾à²–à²²à³† à²à²¨à²¿à²¨ à²¬à²—à³à²—à³†?"
- "[à²¨à²¿à²°à³à²¦à²¿à²·à³à²Ÿ à²µà²¿à²·à²¯] à²¬à²—à³à²—à³† à²¹à³‡à²³à²¿"
- "[à²¨à²¿à²°à³à²¦à²¿à²·à³à²Ÿ à²µà²¿à²·à²¯à²¦] à²¡à³‡à²Ÿà²¾ à²¤à³‹à²°à²¿à²¸à²¿"
- "à²®à³à²–à³à²¯ à²¸à²‚à²¶à³‹à²§à²¨à³†à²—à²³à³ à²à²¨à³?"

à²¨à³€à²µà³ à²à²¨à³ à²¤à²¿à²³à²¿à²¯à²²à³ à²¬à²¯à²¸à³à²¤à³à²¤à³€à²°à²¿?`;

                case 'kannada_roman':
                    return `Namaskara! Upload maadida documents ninda mahitiyanna hudukalu naanu illi iddene. Neevu ee reethiya prashnegalannu kelabahudhu:
- "Ee document yenina bagge?"
- "[specific topic] bagge heli"
- "[specific subject] data thorisi"
- "Main findings yenu?"

Neevu yenu thiliyalu bayasuttheera?`;

                case 'malayalam':
                    return `à´¨à´®à´¸àµà´•à´¾à´°à´‚! à´…à´ªàµâ€Œà´²àµ‹à´¡àµ à´šàµ†à´¯àµà´¤ à´¡àµ‹à´•àµà´¯àµà´®àµ†à´¨àµà´±àµà´•à´³à´¿àµ½ à´¨à´¿à´¨àµà´¨àµà´‚ à´µà´¿à´µà´°à´™àµà´™àµ¾ à´•à´£àµà´Ÿàµ†à´¤àµà´¤à´¾àµ» à´žà´¾àµ» à´‡à´µà´¿à´Ÿàµ†à´¯àµà´£àµà´Ÿàµ. à´¨à´¿à´™àµà´™àµ¾à´•àµà´•àµ à´‡à´¤àµà´¤à´°à´‚ à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾ à´šàµ‹à´¦à´¿à´•àµà´•à´¾à´‚:
- "à´ˆ à´¡àµ‹à´•àµà´¯àµà´®àµ†à´¨àµà´±àµ à´Žà´¨àµà´¤à´¾à´£àµ à´ªà´±à´¯àµà´¨àµà´¨à´¤àµ?"
- "[à´¨à´¿àµ¼à´¦àµà´¦à´¿à´·àµà´Ÿ à´µà´¿à´·à´¯à´‚] à´•àµà´±à´¿à´šàµà´šàµ à´ªà´±à´¯àµ‚"
- "[à´¨à´¿àµ¼à´¦àµà´¦à´¿à´·àµà´Ÿ à´µà´¿à´·à´¯à´¤àµà´¤à´¿à´¨àµà´±àµ†] à´¡à´¾à´±àµà´± à´•à´¾à´£à´¿à´•àµà´•àµ‚"
- "à´ªàµà´°à´§à´¾à´¨ à´•à´£àµà´Ÿàµ†à´¤àµà´¤à´²àµà´•àµ¾ à´Žà´¨àµà´¤à´¾à´£àµ?"

à´Žà´¨àµà´¤à´¾à´£àµ à´…à´±à´¿à´¯àµ‡à´£àµà´Ÿà´¤àµ?`;

                case 'malayalam_roman':
                    return `Namaskaram! Upload cheitha documentukalil ninnum vivarangal kandethan njan evideyund. Ningalkku itharam chodangal chodikam:
- "Ee document enthananu parayunnath?"
- "[specific topic] kurich parayu"
- "[specific subject]nte data kanikku"
- "Pradhana kandethalukal enthananu?"

Enthananu ariyendath?`;

                default:
                    return `Hello! I'm here to help you find information from the uploaded documents. You can ask me questions about the content, such as:
- "What is this document about?"
- "Tell me about [specific topic]"
- "Show me data on [specific subject]"
- "What are the key findings?"

What would you like to know?`;
            }
        }

        // For other queries, provide a more synthesized response based on available content
        const relevantContent = documents.slice(0, 2).map(doc => {
            // Clean up the content and extract meaningful information
            let content = doc.pageContent
                .replace(/TEXT CONTENT:\s*/g, '')
                .replace(/\s+/g, ' ')
                .trim();

            // Try to extract the most relevant portion based on the query
            const queryTerms = query.toLowerCase().split(' ').filter(term => term.length > 2);
            let bestMatch = content.slice(0, 300);

            for (const term of queryTerms) {
                const termIndex = content.toLowerCase().indexOf(term);
                if (termIndex !== -1) {
                    // Extract context around the found term
                    const start = Math.max(0, termIndex - 100);
                    const end = Math.min(content.length, termIndex + 200);
                    bestMatch = content.slice(start, end);
                    break;
                }
            }

            return bestMatch;
        }).filter(content => content.length > 0);

        if (relevantContent.length === 0) {
            return `I found some documents, but they don't seem to contain information directly related to "${query}". Could you try asking about a different topic or provide more specific details about what you're looking for?`;
        }

        return `Based on the available information, here's what I can tell you about "${query}":

${relevantContent.join('\n\n')}

This information comes from the uploaded documents. If you'd like me to elaborate on any specific aspect or if you have follow-up questions, please let me know!`;
    }

    private async assessCompleteness(
        query: string,
        response: string,
        documents: Document[]
    ): Promise<'complete' | 'partial' | 'needs_followup'> {
        const assessmentPrompt = `Assess how completely this response answers the user's query:

User Query: "${query}"
Response: "${response.slice(0, 1000)}..."
Available Evidence: ${documents.length} documents

Rate the completeness:
- "complete": Fully answers the query with sufficient detail
- "partial": Answers part of the query but missing some aspects
- "needs_followup": Raises questions or needs clarification

Consider:
- Does the response directly address what was asked?
- Are there obvious gaps or missing information?
- Would a reasonable person be satisfied with this answer?

Respond with just one word: complete, partial, or needs_followup`;

        try {
            const response_assessment = await synthesisModel.invoke(assessmentPrompt);
            const result = (response_assessment.content as string).toLowerCase().trim();

            if (['complete', 'partial', 'needs_followup'].includes(result)) {
                return result as 'complete' | 'partial' | 'needs_followup';
            }
            return 'partial';
        } catch (error) {
            console.warn('Completeness assessment failed:', error);
            return 'partial';
        }
    }

    private calculateOverallConfidence(reasoningSteps: ReasoningStep[], documentCount: number): number {
        if (reasoningSteps.length === 0) {
            return Math.min(0.8, 0.5 + (documentCount * 0.1));
        }

        const avgStepConfidence = reasoningSteps.reduce((sum, step) => sum + step.confidence, 0) / reasoningSteps.length;
        const documentBonus = Math.min(0.2, documentCount * 0.03);
        const reasoningBonus = Math.min(0.1, reasoningSteps.length * 0.02);

        return Math.min(0.95, avgStepConfidence + documentBonus + reasoningBonus);
    }

    // Utility method for debugging
    getReasoningExplanation(steps: ReasoningStep[]): string {
        return steps.map(step =>
            `${step.step}. ${step.question}\n   â†’ ${step.reasoning}\n   â†’ ${step.conclusion} (${(step.confidence * 100).toFixed(0)}% confidence)`
        ).join('\n\n');
    }
}
