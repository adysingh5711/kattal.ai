import { ChatOpenAI } from "@langchain/openai";
import { Document } from "langchain/document";
import { env } from "./env";
import { QueryAnalysis } from "./query-analyzer";
import { LanguageDetector } from "./language-detector";

const synthesisModel = new ChatOpenAI({
    modelName: env.LLM_MODEL,
    temperature: 0.05, // Very low temperature for precise, consistent responses
    openAIApiKey: env.OPENAI_API_KEY,
    maxTokens: 600, // Increased for more detailed responses
    timeout: 12000, // Increased timeout for deeper analysis
    verbose: false, // Disable verbose for faster processing
});

export interface ResponseSynthesis {
    synthesizedResponse: string;
    reasoningChain: string[];
    confidence: number;
    sourceAttribution: SourceAttribution[];
    responseStyle: 'analytical' | 'explanatory' | 'comparative' | 'narrative';
    completeness: 'complete' | 'partial' | 'needs_followup';
}

type ResponseStyle = 'analytical' | 'explanatory' | 'comparative' | 'narrative';

export interface SourceAttribution {
    source: string;
    relevance: number;
    usedFor: string;
    pageReference?: string;
    contentType: 'text' | 'table' | 'chart' | 'image';
}

export interface ReasoningStep {
    step: number;
    question: string;
    evidence: string[];
    reasoning: string;
    conclusion: string;
    confidence: number;
}

export class ResponseSynthesizer {
    private languageDetector = new LanguageDetector();
    async synthesizeResponse(
        query: string,
        queryAnalysis: QueryAnalysis,
        documents: Document[]
    ): Promise<ResponseSynthesis> {
        console.log(`üîÑ Synthesizing human-like response for: "${query}"`);

        // Step 1: Analyze the evidence and build reasoning chain
        const reasoningSteps = await this.buildReasoningChain(query, queryAnalysis, documents);

        // Step 2: Determine appropriate response style
        const responseStyle = this.determineResponseStyle(queryAnalysis);

        // Step 3: Create source attributions
        const sourceAttributions = this.createSourceAttributions(documents);

        // Step 4: Synthesize the human-like response
        const synthesizedResponse = await this.generateHumanLikeResponse(
            query,
            queryAnalysis,
            documents,
            reasoningSteps,
            responseStyle,
            sourceAttributions
        );

        // Step 5: Assess response completeness and confidence
        const completeness = await this.assessCompleteness(query, synthesizedResponse, documents);
        const confidence = this.calculateOverallConfidence(reasoningSteps, documents.length);

        return {
            synthesizedResponse,
            reasoningChain: reasoningSteps.map(step => step.reasoning),
            confidence,
            sourceAttribution: sourceAttributions,
            responseStyle,
            completeness
        };
    }

    private async buildReasoningChain(
        query: string,
        analysis: QueryAnalysis,
        documents: Document[]
    ): Promise<ReasoningStep[]> {
        // Simplified reasoning for speed - focus on document analysis
        return [{
            step: 1,
            question: query,
            evidence: documents.slice(0, 4).map(doc => doc.pageContent.slice(0, 300)),
            reasoning: "Comprehensive analysis of all available evidence",
            conclusion: "Detailed information extracted from multiple sources",
            confidence: 0.9
        }];

        // Removed complex reasoning chain generation for speed
    }

    private determineResponseStyle(
        analysis: QueryAnalysis
    ): 'analytical' | 'explanatory' | 'comparative' | 'narrative' {
        if (analysis.queryType === 'COMPARATIVE') {
            return 'comparative';
        }
        if (analysis.queryType === 'ANALYTICAL' || analysis.queryType === 'INFERENTIAL') {
            return 'analytical';
        }
        if (analysis.complexity >= 4) {
            return 'narrative';
        }
        return 'explanatory';
    }

    private createSourceAttributions(documents: Document[]): SourceAttribution[] {
        return documents.slice(0, 6).map((doc, index) => {
            const metadata = doc.metadata || {};
            const contentType = this.inferContentType(doc);

            return {
                source: metadata.source || `Document ${index + 1}`,
                relevance: this.calculateSourceRelevance(doc),
                usedFor: this.inferUsageContext(doc, contentType),
                pageReference: metadata.pageNumber ? `Page ${metadata.pageNumber}` : undefined,
                contentType
            };
        });
    }

    private inferContentType(doc: Document): 'text' | 'table' | 'chart' | 'image' {
        const content = doc.pageContent.toLowerCase();
        const metadata = doc.metadata || {};

        if (content.includes('visual analysis:') || metadata.hasVisuals) {
            return 'image';
        }
        if (content.includes('table') || metadata.hasTables) {
            return 'table';
        }
        if (content.includes('chart') || content.includes('graph') || metadata.hasCharts) {
            return 'chart';
        }
        return 'text';
    }

    private calculateSourceRelevance(doc: Document): number {
        const contentLength = doc.pageContent.length;
        const metadata = doc.metadata || {};

        let relevance = 0.5; // Base relevance

        // Boost for longer, more detailed content
        if (contentLength > 1000) relevance += 0.2;
        if (contentLength > 2000) relevance += 0.1;

        // Boost for multimodal content
        if (metadata.hasVisuals) relevance += 0.1;
        if (metadata.hasTables) relevance += 0.1;
        if (metadata.hasCharts) relevance += 0.1;

        return Math.min(1.0, relevance);
    }

    private inferUsageContext(
        doc: Document,
        contentType: 'text' | 'table' | 'chart' | 'image'
    ): string {
        const contextMap: Record<'text' | 'table' | 'chart' | 'image', string> = {
            text: 'background information and context',
            table: 'statistical data and numerical evidence',
            chart: 'trends and visual data analysis',
            image: 'visual evidence and illustrations'
        };

        return contextMap[contentType] ?? 'supporting information';
    }

    private async generateHumanLikeResponse(
        query: string,
        analysis: QueryAnalysis,
        documents: Document[],
        reasoningSteps: ReasoningStep[],
        responseStyle: ResponseStyle,
        sourceAttributions: SourceAttribution[]
    ): Promise<string> {
        const stylePrompts: Record<ResponseStyle, string> = {
            analytical: "Provide a brief, structured response with key points.",
            explanatory: "Give a concise explanation focusing only on the essential information.",
            comparative: "Briefly compare the key differences and similarities.",
            narrative: "Present the information briefly in a logical sequence."
        };

        // Get language-specific instructions
        const languageInstructions = this.languageDetector.getLanguagePromptAddition(analysis.languageDetection);

        const synthesisPrompt = `Create a precise, comprehensive response by analyzing ALL available evidence deeply.

Query: "${query}"
Response Style: ${responseStyle}
Style Guidance: ${stylePrompts[responseStyle]}

DEEP DOCUMENT ANALYSIS - Review ALL evidence thoroughly:
${documents.slice(0, 8).map((doc, i) =>
            `Source ${i + 1} (${sourceAttributions[i]?.contentType || 'text'}): ${doc.pageContent.slice(0, 800)}...`
        ).join('\n\n')}

Reasoning Chain:
${reasoningSteps.map(step =>
            `Step ${step.step}: ${step.question}\nReasoning: ${step.reasoning}\nConclusion: ${step.conclusion}`
        ).join('\n\n')}

${languageInstructions}

PRECISION REQUIREMENTS:

RESPONSE LENGTH:
- Simple questions: 2-3 sentences with specific details
- Complex questions: 4-5 sentences with comprehensive information
- Include relevant data points and specific facts
- Use bullet points for multiple specific facts

CONTENT REQUIREMENTS:
- Answer the specific question with detailed information
- Include relevant data points, numbers, dates, and specific facts
- Cross-reference information from multiple sources when available
- Provide specific examples or evidence when relevant

STRUCTURE:
- Start with the direct answer immediately
- Include supporting details and evidence
- Use bullet points for multiple specific facts
- Reference specific data points and sources

CORRELATION RULES:
- Correlate information from multiple sources to provide comprehensive answers
- Connect related information to give complete context
- Include specific details, numbers, and facts from the documents

Remember: Provide comprehensive, detailed answers by analyzing all available evidence deeply. Include specific facts, data points, and cross-references from the documents.`;

        try {
            const response = await synthesisModel.invoke(synthesisPrompt);
            const content = response.content as string;

            // Validate that we got a proper response, not a generic greeting
            if (content.includes("Hello! How can I help") || content.includes("Hi") || content.length < 50) {
                console.warn('Received generic response, using fallback');
                return this.generateFallbackResponse(query, documents);
            }

            return content;
        } catch (error) {
            console.error('Response synthesis failed:', error);
            return this.generateFallbackResponse(query, documents);
        }
    }

    private generateFallbackResponse(query: string, documents: Document[]): string {
        if (documents.length === 0) {
            return `‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥â‡¥§‡µç‡¥§‡¥∞‡¥Ç ‡¥®‡µΩ‡¥ï‡¥æ‡µª ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥™‡µç‡¥∞‡¥§‡µç‡¥Ø‡µá‡¥ï ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥á‡¥≤‡µç‡¥≤: "${query}". ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥Ç ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‡¥ö‡µã‡¥¶‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï ‡¥Ö‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥¨‡¥®‡µç‡¥ß‡¥™‡µç‡¥™‡µÜ‡¥ü‡µç‡¥ü ‡¥°‡µã‡¥ï‡µç‡¥Ø‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µÅ‡¥ï‡µæ ‡¥∏‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡¥§‡µç‡¥§‡¥ø‡µΩ ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡¥ø‡¥ü‡µç‡¥ü‡µÅ‡¥£‡µç‡¥ü‡µã ‡¥é‡¥®‡µç‡¥®‡µç ‡¥™‡¥∞‡¥ø‡¥∂‡µã‡¥ß‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.`;
        }

        // For simple queries like "hi", provide a helpful response in Malayalam ONLY
        const normalizedQuery = query.toLowerCase().trim();
        if (normalizedQuery === 'hi' || normalizedQuery === 'hello' || normalizedQuery === 'hey' ||
            normalizedQuery === 'namaste' || normalizedQuery === 'namaskar' || normalizedQuery === 'hai' || normalizedQuery === 'helo' ||
            normalizedQuery === 'vanakkam' || normalizedQuery === 'namaskaram' || normalizedQuery === 'namaskara') {

            // STRICT MALAYALAM ONLY - No other language options
            return `‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç! ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥°‡µã‡¥ï‡µç‡¥Ø‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µÅ‡¥ï‡¥≥‡¥ø‡µΩ ‡¥®‡¥ø‡¥®‡µç‡¥®‡µÅ‡¥Ç ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡¥æ‡µª ‡¥û‡¥æ‡µª ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ‡¥Ø‡µÅ‡¥£‡µç‡¥ü‡µç. ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥á‡¥§‡µç‡¥§‡¥∞‡¥Ç ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥ô‡µç‡¥ô‡µæ ‡¥ö‡µã‡¥¶‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡¥Ç:
- "‡¥à ‡¥°‡µã‡¥ï‡µç‡¥Ø‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µç ‡¥é‡¥®‡µç‡¥§‡¥æ‡¥£‡µç ‡¥™‡¥±‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç?"
- "[‡¥®‡¥ø‡µº‡¥¶‡µç‡¥¶‡¥ø‡¥∑‡µç‡¥ü ‡¥µ‡¥ø‡¥∑‡¥Ø‡¥Ç] ‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥™‡¥±‡¥Ø‡µÇ"
- "[‡¥®‡¥ø‡µº‡¥¶‡µç‡¥¶‡¥ø‡¥∑‡µç‡¥ü ‡¥µ‡¥ø‡¥∑‡¥Ø‡¥§‡µç‡¥§‡¥ø‡¥®‡µç‡¥±‡µÜ] ‡¥°‡¥æ‡¥±‡µç‡¥± ‡¥ï‡¥æ‡¥£‡¥ø‡¥ï‡µç‡¥ï‡µÇ"
- "‡¥™‡µç‡¥∞‡¥ß‡¥æ‡¥® ‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡¥≤‡µÅ‡¥ï‡µæ ‡¥é‡¥®‡µç‡¥§‡¥æ‡¥£‡µç?"

‡¥é‡¥®‡µç‡¥§‡¥æ‡¥£‡µç ‡¥Ö‡¥±‡¥ø‡¥Ø‡µá‡¥£‡µç‡¥ü‡¥§‡µç?`;
        }

        // For other queries, provide a more synthesized response based on available content in Malayalam
        const relevantContent = documents.slice(0, 2).map(doc => {
            // Clean up the content and extract meaningful information
            const content = doc.pageContent
                .replace(/TEXT CONTENT:\s*/g, '')
                .replace(/\s+/g, ' ')
                .trim();

            // Try to extract the most relevant portion based on the query
            const queryTerms = query.toLowerCase().split(' ').filter(term => term.length > 2);
            let bestMatch = content.slice(0, 300);

            for (const term of queryTerms) {
                const termIndex = content.toLowerCase().indexOf(term);
                if (termIndex !== -1) {
                    // Extract context around the found term
                    const start = Math.max(0, termIndex - 100);
                    const end = Math.min(content.length, termIndex + 200);
                    bestMatch = content.slice(start, end);
                    break;
                }
            }

            return bestMatch;
        }).filter(content => content.length > 0);

        if (relevantContent.length === 0) {
            return `‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥ö‡¥ø‡¥≤ ‡¥°‡µã‡¥ï‡µç‡¥Ø‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µÅ‡¥ï‡µæ ‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡¥ø, ‡¥™‡¥ï‡µç‡¥∑‡µá ‡¥Ö‡¥µ "${query}" ‡¥é‡¥®‡µç‡¥®‡¥§‡µÅ‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥®‡µá‡¥∞‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥¨‡¥®‡µç‡¥ß‡¥™‡µç‡¥™‡µÜ‡¥ü‡µç‡¥ü ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥Ö‡¥ü‡¥ô‡µç‡¥ô‡¥ø‡¥Ø‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥§‡¥æ‡¥Ø‡¥ø ‡¥§‡µã‡¥®‡µç‡¥®‡µÅ‡¥®‡µç‡¥®‡¥ø‡¥≤‡µç‡¥≤. ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥µ‡µç‡¥Ø‡¥§‡µç‡¥Ø‡¥∏‡µç‡¥§ ‡¥µ‡¥ø‡¥∑‡¥Ø‡¥§‡µç‡¥§‡µÜ‡¥ï‡µç‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥ö‡µã‡¥¶‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï ‡¥Ö‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ ‡¥§‡¥ø‡¥∞‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡¥ø‡¥®‡µÜ‡¥ï‡µç‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥ï‡µÇ‡¥ü‡µÅ‡¥§‡µΩ ‡¥®‡¥ø‡µº‡¥¶‡µç‡¥¶‡¥ø‡¥∑‡µç‡¥ü ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥®‡µΩ‡¥ï‡µÅ‡¥ï.`;
        }

        return `‡¥≤‡¥≠‡µç‡¥Ø‡¥Æ‡¥æ‡¥Ø ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥Ö‡¥ü‡¥ø‡¥∏‡µç‡¥•‡¥æ‡¥®‡¥§‡µç‡¥§‡¥ø‡µΩ, "${query}" ‡¥é‡¥®‡µç‡¥®‡¥§‡¥ø‡¥®‡µÜ‡¥ï‡µç‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥™‡¥±‡¥Ø‡¥æ‡µª ‡¥ï‡¥¥‡¥ø‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç:

${relevantContent.join('\n\n')}

‡¥à ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥°‡µã‡¥ï‡µç‡¥Ø‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µÅ‡¥ï‡¥≥‡¥ø‡µΩ ‡¥®‡¥ø‡¥®‡µç‡¥®‡¥æ‡¥£‡µç. ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥è‡¥§‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡¥≤‡µÅ‡¥Ç ‡¥®‡¥ø‡µº‡¥¶‡µç‡¥¶‡¥ø‡¥∑‡µç‡¥ü ‡¥µ‡¥∂‡¥§‡µç‡¥§‡µÜ‡¥ï‡µç‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥µ‡¥ø‡¥∂‡¥¶‡µÄ‡¥ï‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥Ü‡¥ó‡µç‡¥∞‡¥π‡¥Æ‡µÅ‡¥£‡µç‡¥ü‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥Ö‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥§‡µÅ‡¥ü‡µº‡¥®‡µç‡¥®‡µÅ‡¥≥‡µç‡¥≥ ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥ô‡µç‡¥ô‡µæ ‡¥â‡¥£‡µç‡¥ü‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ, ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥é‡¥®‡µç‡¥®‡µÜ ‡¥Ö‡¥±‡¥ø‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï!`;
    }

    private async assessCompleteness(
        query: string,
        response: string,
        documents: Document[]
    ): Promise<'complete' | 'partial' | 'needs_followup'> {
        const assessmentPrompt = `Assess how completely this response answers the user's query:

User Query: "${query}"
Response: "${response.slice(0, 1000)}..."
Available Evidence: ${documents.length} documents

Rate the completeness:
- "complete": Fully answers the query with sufficient detail
- "partial": Answers part of the query but missing some aspects
- "needs_followup": Raises questions or needs clarification

Consider:
- Does the response directly address what was asked?
- Are there obvious gaps or missing information?
- Would a reasonable person be satisfied with this answer?

Respond with just one word: complete, partial, or needs_followup`;

        try {
            const response_assessment = await synthesisModel.invoke(assessmentPrompt);
            const result = (response_assessment.content as string).toLowerCase().trim();

            if (['complete', 'partial', 'needs_followup'].includes(result)) {
                return result as 'complete' | 'partial' | 'needs_followup';
            }
            return 'partial';
        } catch (error) {
            console.warn('Completeness assessment failed:', error);
            return 'partial';
        }
    }

    private calculateOverallConfidence(reasoningSteps: ReasoningStep[], documentCount: number): number {
        if (reasoningSteps.length === 0) {
            return Math.min(0.8, 0.5 + (documentCount * 0.1));
        }

        const avgStepConfidence = reasoningSteps.reduce((sum, step) => sum + step.confidence, 0) / reasoningSteps.length;
        const documentBonus = Math.min(0.2, documentCount * 0.03);
        const reasoningBonus = Math.min(0.1, reasoningSteps.length * 0.02);

        return Math.min(0.95, avgStepConfidence + documentBonus + reasoningBonus);
    }

    // Utility method for debugging
    getReasoningExplanation(steps: ReasoningStep[]): string {
        return steps.map(step =>
            `${step.step}. ${step.question}\n   ‚Üí ${step.reasoning}\n   ‚Üí ${step.conclusion} (${(step.confidence * 100).toFixed(0)}% confidence)`
        ).join('\n\n');
    }
}
