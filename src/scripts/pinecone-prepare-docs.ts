import { getChunkedDocsFromPDF, getChunkedDocsIncrementally } from "@/lib/pdf-loader";
import { embedAndStoreDocs } from "@/lib/vector-store";
import { getPinecone } from "@/lib/pinecone-client";

// Enhanced script that supports both full rebuild and incremental updates
// Usage:
// - npm run docs:prepare - Incremental update (default)
// - npm run docs:prepare:full - Full rebuild (legacy mode)

const mode = process.argv[2] || 'incremental';

// This operation might fail because indexes likely need
// more time to init, so give some 5 mins after index
// creation and try again.
(async () => {
    try {
        const pineconeClient = await getPinecone();
        console.log("ğŸ”— Connected to Pinecone");

        if (mode === 'full' || mode === 'legacy') {
            console.log("\nğŸ”„ Running in FULL REBUILD mode...");
            console.log("âš ï¸  This will process ALL documents regardless of changes");

            console.log("\nğŸ“„ Preparing chunks from PDF files...");
            const docs = await getChunkedDocsFromPDF();

            console.log(`\nğŸš€ Loading ${docs.length} chunks into Pinecone...`);

            // Validate document sizes before processing
            const oversizedDocs = docs.filter(doc => doc.pageContent.length > 6000);
            if (oversizedDocs.length > 0) {
                console.warn(`âš ï¸  Found ${oversizedDocs.length} documents that may be too large for embedding`);
            }

            await embedAndStoreDocs(pineconeClient, docs);
            console.log("\nâœ… Data embedded and stored in Pinecone index");
        } else {
            console.log("\nğŸ”„ Running in INCREMENTAL mode...");
            console.log("âœ… Only new or changed documents will be processed");

            const result = await getChunkedDocsIncrementally({
                enableBackup: true,
                batchSize: 50
            });

            console.log('\nğŸ“Š INCREMENTAL UPDATE SUMMARY:');
            console.log('='.repeat(50));
            console.log(`ğŸ“ˆ Total Documents: ${result.updateResult.totalDocuments}`);
            console.log(`â• New Documents: ${result.updateResult.newDocuments}`);
            console.log(`ğŸ”„ Updated Documents: ${result.updateResult.updatedDocuments}`);
            console.log(`â­ï¸  Skipped Documents: ${result.updateResult.skippedDocuments}`);
            console.log(`ğŸ“¦ Processed Chunks: ${result.updateResult.processedChunks}`);
            console.log(`â±ï¸  Processing Time: ${(result.updateResult.processingTime / 1000).toFixed(2)}s`);
            console.log('='.repeat(50));

            if (result.updateResult.newDocuments === 0 && result.updateResult.updatedDocuments === 0) {
                console.log("âœ¨ No new or updated documents found - all data is up to date!");
            }
        }

        console.log("ğŸ‰ Processing completed successfully!");

        // Show usage tips
        console.log("\nğŸ’¡ Usage Tips:");
        console.log("- Use `npm run docs:prepare` for incremental updates (recommended)");
        console.log("- Use `npm run docs:prepare full` for complete rebuild");
        console.log("- Use `npm run docs:status` to check current document status");

    } catch (error) {
        console.error("âŒ Document preparation failed:", error);
        process.exit(1);
    }
})();